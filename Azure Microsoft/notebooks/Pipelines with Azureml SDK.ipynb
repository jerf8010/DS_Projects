{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b00c1d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.38.0 to work with Azureml-SDK-WS02\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "import azureml.core\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b28cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaults_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'defaults_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70568f71",
   "metadata": {},
   "source": [
    "# Compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f2b5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = 'my-cluster-001'\n",
    "\n",
    "try:\n",
    "    compute_cluster = ComputeTarget(workspace = ws,\n",
    "                                   name = cluster_name)\n",
    "    print('Found existing cluster, use it')\n",
    "except ComputeTargetException:\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size = 'STANDARD_DS11_V',\n",
    "                                                              max_nodes = 2)\n",
    "        compute_cluster = ComputeTarget.create(ws,\n",
    "                                              cluster_name,\n",
    "                                              compute_config)\n",
    "        compute_cluster.wait_for_completion(show_output = True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b37856",
   "metadata": {},
   "source": [
    "# Register Environment (Other way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "171d5c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing defaults_pipeline/experiment_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/experiment_env.yml\n",
    "name: experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n",
    "  - pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5adec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/experiment_env.yml\")\n",
    "experiment_env.register(workspace=ws)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1864bfd",
   "metadata": {},
   "source": [
    "# Register Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "050a50d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"MyEnvironment\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.6.2\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults~=1.38.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn\",\n",
       "                \"pandas\",\n",
       "                \"numpy\"\n",
       "            ],\n",
       "            \"name\": \"azureml_d9271587e78e8fd4e49fcb4d1af951bc\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"3\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Environment, Experiment, ScriptRunConfig\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.environment import CondaDependencies\n",
    "\n",
    "\n",
    "myenv = Environment(name = 'MyEnvironment')\n",
    "\n",
    "myenv_dep = CondaDependencies.create(conda_packages = ['scikit-learn',\n",
    "                                                      'pandas',\n",
    "                                                      'numpy'])\n",
    "myenv.python.conda_dependencies = myenv_dep\n",
    "myenv.register(ws)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7afdd",
   "metadata": {},
   "source": [
    "# Create Run Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7b62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = RunConfiguration()\n",
    "run_config.target = compute_cluster\n",
    "run_config.environment = myenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f90c2",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bc73daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 245 files\n",
      "Uploading ./.amlignore\n",
      "Uploaded ./.amlignore, 1 files out of an estimated total of 245\n",
      "Uploading ./.amlignore.amltmp\n",
      "Uploaded ./.amlignore.amltmp, 2 files out of an estimated total of 245\n",
      "Uploading ./Compute_Cluster with SDK.ipynb\n",
      "Uploaded ./Compute_Cluster with SDK.ipynb, 3 files out of an estimated total of 245\n",
      "Uploading ./Experiments SDK.ipynb\n",
      "Uploaded ./Experiments SDK.ipynb, 4 files out of an estimated total of 245\n",
      "Uploading ./Experiments AzureML SDK 1.ipynb\n",
      "Uploaded ./Experiments AzureML SDK 1.ipynb, 5 files out of an estimated total of 245\n",
      "Uploading ./Set up AzureML Workspace.ipynb\n",
      "Uploaded ./Set up AzureML Workspace.ipynb, 6 files out of an estimated total of 245\n",
      "Uploading ./Test-Bikes.ipynb\n",
      "Uploaded ./Test-Bikes.ipynb, 7 files out of an estimated total of 245\n",
      "Uploading ./test-bikes.ipynb.amltmp\n",
      "Uploaded ./test-bikes.ipynb.amltmp, 8 files out of an estimated total of 245\n",
      "Uploading ./Untitled.ipynb\n",
      "Uploaded ./Untitled.ipynb, 9 files out of an estimated total of 245\n",
      "Uploading ./untitled.ipynb.amltmp\n",
      "Uploaded ./untitled.ipynb.amltmp, 10 files out of an estimated total of 245\n",
      "Uploading ./.azureml/config.json\n",
      "Uploaded ./.azureml/config.json, 11 files out of an estimated total of 245\n",
      "Uploading ./.ipynb_aml_checkpoints/Test-Bikes-checkpoint2022-2-6-9-5-20Z.ipynb\n",
      "Uploaded ./.ipynb_aml_checkpoints/Test-Bikes-checkpoint2022-2-6-9-5-20Z.ipynb, 12 files out of an estimated total of 245\n",
      "Uploading ./.ipynb_aml_checkpoints/Untitled-checkpoint2022-2-7-4-25-11Z.ipynb\n",
      "Uploaded ./.ipynb_aml_checkpoints/Untitled-checkpoint2022-2-7-4-25-11Z.ipynb, 13 files out of an estimated total of 245\n",
      "Uploading ./.ipynb_checkpoints/Compute_Cluster with SDK-checkpoint.ipynb\n",
      "Uploaded ./.ipynb_checkpoints/Compute_Cluster with SDK-checkpoint.ipynb, 14 files out of an estimated total of 245\n",
      "Uploading ./defaults.csv\n",
      "Uploaded ./defaults.csv, 15 files out of an estimated total of 245\n",
      "Uploading ./training_model_AzureML_SDK.ipynb\n",
      "Uploaded ./training_model_AzureML_SDK.ipynb, 16 files out of an estimated total of 245\n",
      "Uploading ./Untitled1.ipynb\n",
      "Uploaded ./Untitled1.ipynb, 17 files out of an estimated total of 245\n",
      "Uploading ./.ipynb_checkpoints/Experiments AzureML SDK 1-checkpoint.ipynb\n",
      "Uploaded ./.ipynb_checkpoints/Experiments AzureML SDK 1-checkpoint.ipynb, 18 files out of an estimated total of 245\n",
      "Uploading ./.ipynb_checkpoints/Experiments SDK-checkpoint.ipynb\n",
      "Uploaded ./.ipynb_checkpoints/Experiments SDK-checkpoint.ipynb, 19 files out of an estimated total of 245\n",
      "Uploading ./.ipynb_checkpoints/Set up AzureML Workspace-checkpoint.ipynb\n",
      "Uploaded ./.ipynb_checkpoints/Set up AzureML Workspace-checkpoint.ipynb, 20 files out of an estimated total of 245\n",
      "Uploading ./.ipynb_checkpoints/Untitled1-checkpoint.ipynb\n",
      "Uploaded ./.ipynb_checkpoints/Untitled1-checkpoint.ipynb, 21 files out of an estimated total of 245\n",
      "Uploading ./defaults_pipeline/experiment_env.yml\n",
      "Uploaded ./defaults_pipeline/experiment_env.yml, 22 files out of an estimated total of 245\n",
      "Uploading ./loan/Loan Approval Prediction.csv\n",
      "Uploaded ./loan/Loan Approval Prediction.csv, 23 files out of an estimated total of 245\n",
      "Uploading ./loan/loan_training.py\n",
      "Uploaded ./loan/loan_training.py, 24 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.amlignore\n",
      "Uploaded ./mslearn-dp100/.amlignore, 25 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.amlignore.amltmp\n",
      "Uploaded ./mslearn-dp100/.amlignore.amltmp, 26 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.gitignore\n",
      "Uploaded ./mslearn-dp100/.gitignore, 27 files out of an estimated total of 245\n",
      "Uploading ./.ipynb_checkpoints/training_model_AzureML_SDK-checkpoint.ipynb\n",
      "Uploaded ./.ipynb_checkpoints/training_model_AzureML_SDK-checkpoint.ipynb, 28 files out of an estimated total of 245\n",
      "Uploading ./loan/loan.csv\n",
      "Uploaded ./loan/loan.csv, 29 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/01 - Get Started with Notebooks.ipynb\n",
      "Uploaded ./mslearn-dp100/01 - Get Started with Notebooks.ipynb, 30 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/01 - get started with notebooks.ipynb.amltmp\n",
      "Uploaded ./mslearn-dp100/01 - get started with notebooks.ipynb.amltmp, 31 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/02 - Get AutoML Prediction.ipynb\n",
      "Uploaded ./mslearn-dp100/02 - Get AutoML Prediction.ipynb, 32 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/02 - get automl prediction.ipynb.amltmp\n",
      "Uploaded ./mslearn-dp100/02 - get automl prediction.ipynb.amltmp, 33 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/03 - Get Designer Prediction.ipynb\n",
      "Uploaded ./mslearn-dp100/03 - Get Designer Prediction.ipynb, 34 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/05 - Train Models.ipynb\n",
      "Uploaded ./mslearn-dp100/05 - Train Models.ipynb, 35 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/06 - Work with Data.ipynb\n",
      "Uploaded ./mslearn-dp100/06 - Work with Data.ipynb, 36 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/07 - Work with Compute.ipynb\n",
      "Uploaded ./mslearn-dp100/07 - Work with Compute.ipynb, 37 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/08 - Create a Pipeline.ipynb\n",
      "Uploaded ./mslearn-dp100/08 - Create a Pipeline.ipynb, 38 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/09 - Create a Real-time Inferencing Service.ipynb\n",
      "Uploaded ./mslearn-dp100/09 - Create a Real-time Inferencing Service.ipynb, 39 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/11 - Tune Hyperparameters.ipynb\n",
      "Uploaded ./mslearn-dp100/11 - Tune Hyperparameters.ipynb, 40 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/12 - Use Automated Machine Learning.ipynb\n",
      "Uploaded ./mslearn-dp100/12 - Use Automated Machine Learning.ipynb, 41 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/13 - Explore Differential Privacy.ipynb\n",
      "Uploaded ./mslearn-dp100/13 - Explore Differential Privacy.ipynb, 42 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/14 - Interpret Models.ipynb\n",
      "Uploaded ./mslearn-dp100/14 - Interpret Models.ipynb, 43 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/04 - Run Experiments.ipynb\n",
      "Uploaded ./mslearn-dp100/04 - Run Experiments.ipynb, 44 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/10 - Create a Batch Inferencing Service.ipynb\n",
      "Uploaded ./mslearn-dp100/10 - Create a Batch Inferencing Service.ipynb, 45 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/15 - Detect Unfairness.ipynb\n",
      "Uploaded ./mslearn-dp100/15 - Detect Unfairness.ipynb, 46 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/16 - Monitor a Model.ipynb\n",
      "Uploaded ./mslearn-dp100/16 - Monitor a Model.ipynb, 47 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/17 - Monitor Data Drift.ipynb\n",
      "Uploaded ./mslearn-dp100/17 - Monitor Data Drift.ipynb, 48 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes_model.pkl\n",
      "Uploaded ./mslearn-dp100/diabetes_model.pkl, 49 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/environment.yml\n",
      "Uploaded ./mslearn-dp100/environment.yml, 50 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/index.md\n",
      "Uploaded ./mslearn-dp100/index.md, 51 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/LICENSE\n",
      "Uploaded ./mslearn-dp100/LICENSE, 52 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/README.md\n",
      "Uploaded ./mslearn-dp100/README.md, 53 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/sample.csv\n",
      "Uploaded ./mslearn-dp100/sample.csv, 54 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/Untitled.ipynb\n",
      "Uploaded ./mslearn-dp100/Untitled.ipynb, 55 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/_build.yml\n",
      "Uploaded ./mslearn-dp100/_build.yml, 56 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/_config.yml\n",
      "Uploaded ./mslearn-dp100/_config.yml, 57 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/config\n",
      "Uploaded ./mslearn-dp100/.git/config, 58 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/description\n",
      "Uploaded ./mslearn-dp100/.git/description, 59 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/HEAD\n",
      "Uploaded ./mslearn-dp100/.git/HEAD, 60 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/index\n",
      "Uploaded ./mslearn-dp100/.git/index, 61 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/packed-refs\n",
      "Uploaded ./mslearn-dp100/.git/packed-refs, 62 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/applypatch-msg.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/applypatch-msg.sample, 63 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/commit-msg.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/commit-msg.sample, 64 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/fsmonitor-watchman.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/fsmonitor-watchman.sample, 65 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/post-update.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/post-update.sample, 66 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/pre-applypatch.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/pre-applypatch.sample, 67 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/pre-commit.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/pre-commit.sample, 68 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/pre-merge-commit.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/pre-merge-commit.sample, 69 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/pre-push.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/pre-push.sample, 70 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/pre-rebase.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/pre-rebase.sample, 71 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/pre-receive.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/pre-receive.sample, 72 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/prepare-commit-msg.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/prepare-commit-msg.sample, 73 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/push-to-checkout.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/push-to-checkout.sample, 74 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/hooks/update.sample\n",
      "Uploaded ./mslearn-dp100/.git/hooks/update.sample, 75 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/info/exclude\n",
      "Uploaded ./mslearn-dp100/.git/info/exclude, 76 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/logs/HEAD\n",
      "Uploaded ./mslearn-dp100/.git/logs/HEAD, 77 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/logs/refs/heads/main\n",
      "Uploaded ./mslearn-dp100/.git/logs/refs/heads/main, 78 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/logs/refs/remotes/origin/HEAD\n",
      "Uploaded ./mslearn-dp100/.git/logs/refs/remotes/origin/HEAD, 79 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/objects/pack/pack-3b5b0d5056aad14dfb6fd6ab4f85b37a609ef486.idx\n",
      "Uploaded ./mslearn-dp100/.git/objects/pack/pack-3b5b0d5056aad14dfb6fd6ab4f85b37a609ef486.idx, 80 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/refs/heads/main\n",
      "Uploaded ./mslearn-dp100/.git/refs/heads/main, 81 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/refs/remotes/origin/HEAD\n",
      "Uploaded ./mslearn-dp100/.git/refs/remotes/origin/HEAD, 82 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_aml_checkpoints/01 - Get Started with Notebooks-checkpoint2022-2-8-1-29-3Z.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_aml_checkpoints/01 - Get Started with Notebooks-checkpoint2022-2-8-1-29-3Z.ipynb, 83 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_aml_checkpoints/02 - Get AutoML Prediction-checkpoint2022-2-8-1-29-41Z.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_aml_checkpoints/02 - Get AutoML Prediction-checkpoint2022-2-8-1-29-41Z.ipynb, 84 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_aml_checkpoints/03 - Get Designer Prediction-checkpoint2022-2-8-1-29-41Z.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_aml_checkpoints/03 - Get Designer Prediction-checkpoint2022-2-8-1-29-41Z.ipynb, 85 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_checkpoints/04 - Run Experiments-checkpoint.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_checkpoints/04 - Run Experiments-checkpoint.ipynb, 86 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_checkpoints/05 - Train Models-checkpoint.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_checkpoints/05 - Train Models-checkpoint.ipynb, 87 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_checkpoints/06 - Work with Data-checkpoint.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_checkpoints/06 - Work with Data-checkpoint.ipynb, 88 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_checkpoints/07 - Work with Compute-checkpoint.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_checkpoints/07 - Work with Compute-checkpoint.ipynb, 89 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_checkpoints/08 - Create a Pipeline-checkpoint.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_checkpoints/08 - Create a Pipeline-checkpoint.ipynb, 90 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_checkpoints/09 - Create a Real-time Inferencing Service-checkpoint.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_checkpoints/09 - Create a Real-time Inferencing Service-checkpoint.ipynb, 91 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_checkpoints/Untitled-checkpoint.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_checkpoints/Untitled-checkpoint.ipynb, 92 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/1.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/1.csv, 93 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.ipynb_checkpoints/10 - Create a Batch Inferencing Service-checkpoint.ipynb\n",
      "Uploaded ./mslearn-dp100/.ipynb_checkpoints/10 - Create a Batch Inferencing Service-checkpoint.ipynb, 94 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/10.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/10.csv, 95 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/100.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/100.csv, 96 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/11.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/11.csv, 97 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/12.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/12.csv, 98 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/13.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/13.csv, 99 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/14.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/14.csv, 100 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/15.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/15.csv, 101 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/16.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/16.csv, 102 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/17.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/17.csv, 103 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/18.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/18.csv, 104 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/19.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/19.csv, 105 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/2.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/2.csv, 106 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/20.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/20.csv, 107 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/21.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/21.csv, 108 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/22.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/22.csv, 109 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/23.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/23.csv, 110 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/24.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/24.csv, 111 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/25.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/25.csv, 112 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/26.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/26.csv, 113 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/27.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/27.csv, 114 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/28.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/28.csv, 115 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/29.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/29.csv, 116 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/3.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/3.csv, 117 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/30.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/30.csv, 118 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/31.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/31.csv, 119 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/32.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/32.csv, 120 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/33.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/33.csv, 121 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/34.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/34.csv, 122 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/35.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/35.csv, 123 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/38.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/38.csv, 124 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/.git/objects/pack/pack-3b5b0d5056aad14dfb6fd6ab4f85b37a609ef486.pack\n",
      "Uploaded ./mslearn-dp100/.git/objects/pack/pack-3b5b0d5056aad14dfb6fd6ab4f85b37a609ef486.pack, 125 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/36.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/36.csv, 126 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/37.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/37.csv, 127 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/39.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/39.csv, 128 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/4.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/4.csv, 129 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/40.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/40.csv, 130 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/41.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/41.csv, 131 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/42.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/42.csv, 132 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/43.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/43.csv, 133 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/44.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/44.csv, 134 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/45.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/45.csv, 135 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/46.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/46.csv, 136 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/47.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/47.csv, 137 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/48.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/48.csv, 138 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/49.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/49.csv, 139 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/5.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/5.csv, 140 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/50.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/50.csv, 141 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/51.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/51.csv, 142 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/52.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/52.csv, 143 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/53.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/53.csv, 144 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/54.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/54.csv, 145 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/55.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/55.csv, 146 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/56.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/56.csv, 147 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/57.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/57.csv, 148 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/58.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/58.csv, 149 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/59.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/59.csv, 150 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/6.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/6.csv, 151 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/60.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/60.csv, 152 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/61.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/61.csv, 153 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/62.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/62.csv, 154 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/63.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/63.csv, 155 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/64.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/64.csv, 156 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/65.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/65.csv, 157 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/66.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/66.csv, 158 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/67.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/67.csv, 159 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/68.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/68.csv, 160 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/69.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/69.csv, 161 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/7.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/7.csv, 162 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/70.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/70.csv, 163 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/71.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/71.csv, 164 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/72.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/72.csv, 165 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/73.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/73.csv, 166 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/74.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/74.csv, 167 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/75.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/75.csv, 168 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/76.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/76.csv, 169 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/77.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/77.csv, 170 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/78.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/78.csv, 171 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/79.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/79.csv, 172 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/8.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/8.csv, 173 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/80.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/80.csv, 174 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/81.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/81.csv, 175 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/82.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/82.csv, 176 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/83.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/83.csv, 177 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/84.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/84.csv, 178 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/85.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/85.csv, 179 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/86.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/86.csv, 180 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/87.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/87.csv, 181 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/88.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/88.csv, 182 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/89.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/89.csv, 183 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/9.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/9.csv, 184 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/90.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/90.csv, 185 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/91.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/91.csv, 186 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/92.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/92.csv, 187 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/93.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/93.csv, 188 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/94.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/94.csv, 189 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/95.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/95.csv, 190 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/96.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/96.csv, 191 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/97.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/97.csv, 192 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/98.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/98.csv, 193 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch-data/99.csv\n",
      "Uploaded ./mslearn-dp100/batch-data/99.csv, 194 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch_pipeline/batch_diabetes.py\n",
      "Uploaded ./mslearn-dp100/batch_pipeline/batch_diabetes.py, 195 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/batch_pipeline/batch_environment.yml\n",
      "Uploaded ./mslearn-dp100/batch_pipeline/batch_environment.yml, 196 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/data/data.csv\n",
      "Uploaded ./mslearn-dp100/data/data.csv, 197 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes-experiment-files/diabetes_experiment.py\n",
      "Uploaded ./mslearn-dp100/diabetes-experiment-files/diabetes_experiment.py, 198 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes-results/dataset/88f3fec2-3c70-4b7d-abed-e10a0f1d9d2a/inferences/parallel_run_step.txt\n",
      "Uploaded ./mslearn-dp100/diabetes-results/dataset/88f3fec2-3c70-4b7d-abed-e10a0f1d9d2a/inferences/parallel_run_step.txt, 199 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes-training/diabetes_training.py\n",
      "Uploaded ./mslearn-dp100/diabetes-training/diabetes_training.py, 200 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes-training-params/diabetes_training.py\n",
      "Uploaded ./mslearn-dp100/diabetes-training-params/diabetes_training.py, 201 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes_pipeline/experiment_env.yml\n",
      "Uploaded ./mslearn-dp100/diabetes_pipeline/experiment_env.yml, 202 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/data/diabetes.csv\n",
      "Uploaded ./mslearn-dp100/data/diabetes.csv, 203 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/data/diabetes2.csv\n",
      "Uploaded ./mslearn-dp100/data/diabetes2.csv, 204 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes_pipeline/prep_diabetes.py\n",
      "Uploaded ./mslearn-dp100/diabetes_pipeline/prep_diabetes.py, 205 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes_pipeline/train_diabetes.py\n",
      "Uploaded ./mslearn-dp100/diabetes_pipeline/train_diabetes.py, 206 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes_service/score_diabetes.py\n",
      "Uploaded ./mslearn-dp100/diabetes_service/score_diabetes.py, 207 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes_training_from_file_dataset/diabetes_training.py\n",
      "Uploaded ./mslearn-dp100/diabetes_training_from_file_dataset/diabetes_training.py, 208 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes_training_from_tab_dataset/diabetes_training.py\n",
      "Uploaded ./mslearn-dp100/diabetes_training_from_tab_dataset/diabetes_training.py, 209 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes_training_logistic/diabetes_training.py\n",
      "Uploaded ./mslearn-dp100/diabetes_training_logistic/diabetes_training.py, 210 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes_training_logistic/experiment_env.yml\n",
      "Uploaded ./mslearn-dp100/diabetes_training_logistic/experiment_env.yml, 211 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes-training/diabetes.csv\n",
      "Uploaded ./mslearn-dp100/diabetes-training/diabetes.csv, 212 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes_training_tree/diabetes_training.py\n",
      "Uploaded ./mslearn-dp100/diabetes_training_tree/diabetes_training.py, 213 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/downloaded-files/outputs/sample.csv\n",
      "Uploaded ./mslearn-dp100/downloaded-files/outputs/sample.csv, 214 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/downloaded-logs/azureml-logs/60_control_log.txt\n",
      "Uploaded ./mslearn-dp100/downloaded-logs/azureml-logs/60_control_log.txt, 215 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/downloaded-logs/azureml-logs/70_driver_log.txt\n",
      "Uploaded ./mslearn-dp100/downloaded-logs/azureml-logs/70_driver_log.txt, 216 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/downloaded-logs/logs/azureml/29182_azureml.log\n",
      "Uploaded ./mslearn-dp100/downloaded-logs/logs/azureml/29182_azureml.log, 217 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/01-create-a-workspace.md\n",
      "Uploaded ./mslearn-dp100/instructions/01-create-a-workspace.md, 218 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/02-automated-ml.md\n",
      "Uploaded ./mslearn-dp100/instructions/02-automated-ml.md, 219 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes-experiment-files/diabetes.csv\n",
      "Uploaded ./mslearn-dp100/diabetes-experiment-files/diabetes.csv, 220 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/03-azureml-designer.md\n",
      "Uploaded ./mslearn-dp100/instructions/03-azureml-designer.md, 221 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/04-run-experiments.md\n",
      "Uploaded ./mslearn-dp100/instructions/04-run-experiments.md, 222 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/05-train-models.md\n",
      "Uploaded ./mslearn-dp100/instructions/05-train-models.md, 223 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/06-work-with-data.md\n",
      "Uploaded ./mslearn-dp100/instructions/06-work-with-data.md, 224 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/07-work-with-compute.md\n",
      "Uploaded ./mslearn-dp100/instructions/07-work-with-compute.md, 225 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/08-create-a-pipeline.md\n",
      "Uploaded ./mslearn-dp100/instructions/08-create-a-pipeline.md, 226 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/09-create-realtime-service.md\n",
      "Uploaded ./mslearn-dp100/instructions/09-create-realtime-service.md, 227 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/10-create-batch-service.md\n",
      "Uploaded ./mslearn-dp100/instructions/10-create-batch-service.md, 228 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/11-tune-hyperparameters.md\n",
      "Uploaded ./mslearn-dp100/instructions/11-tune-hyperparameters.md, 229 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/12-use-automl.md\n",
      "Uploaded ./mslearn-dp100/instructions/12-use-automl.md, 230 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/13-explore-differential-privacy.md\n",
      "Uploaded ./mslearn-dp100/instructions/13-explore-differential-privacy.md, 231 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/14-interpret-models.md\n",
      "Uploaded ./mslearn-dp100/instructions/14-interpret-models.md, 232 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/15-detect-unfairness.md\n",
      "Uploaded ./mslearn-dp100/instructions/15-detect-unfairness.md, 233 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/16-monitor-a-model.md\n",
      "Uploaded ./mslearn-dp100/instructions/16-monitor-a-model.md, 234 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/17-monitor-data-drift.md\n",
      "Uploaded ./mslearn-dp100/instructions/17-monitor-data-drift.md, 235 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/diabetes-training-params/diabetes.csv\n",
      "Uploaded ./mslearn-dp100/diabetes-training-params/diabetes.csv, 236 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/cheat-sheets/dp100-cheat-sheet-machine-learning.pdf\n",
      "Uploaded ./mslearn-dp100/instructions/cheat-sheets/dp100-cheat-sheet-machine-learning.pdf, 237 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/images/visual-inference.jpg\n",
      "Uploaded ./mslearn-dp100/instructions/images/visual-inference.jpg, 238 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/images/visual-training.jpg\n",
      "Uploaded ./mslearn-dp100/instructions/images/visual-training.jpg, 239 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/metadata/diabetes.yml\n",
      "Uploaded ./mslearn-dp100/metadata/diabetes.yml, 240 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/mlflow-experiment-files/mlflow_diabetes.py\n",
      "Uploaded ./mslearn-dp100/mlflow-experiment-files/mlflow_diabetes.py, 241 files out of an estimated total of 245\n",
      "Uploading ./outputs/loan_model.pkl\n",
      "Uploaded ./outputs/loan_model.pkl, 242 files out of an estimated total of 245\n",
      "Uploading ./outputs/Loan_scored.csv\n",
      "Uploaded ./outputs/Loan_scored.csv, 243 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/instructions/cheat-sheets/dp100-cheat-sheet-python.pdf\n",
      "Uploaded ./mslearn-dp100/instructions/cheat-sheets/dp100-cheat-sheet-python.pdf, 244 files out of an estimated total of 245\n",
      "Uploading ./mslearn-dp100/mlflow-experiment-files/diabetes.csv\n",
      "Uploaded ./mslearn-dp100/mlflow-experiment-files/diabetes.csv, 245 files out of an estimated total of 245\n",
      "Uploaded 245 files\n",
      "Dataset registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'defaults dataset' not in ws.datasets:\n",
    "    default_ds.upload(src_dir = '.',\n",
    "                     target_path = 'defaults',\n",
    "                     overwrite = True,\n",
    "                     show_progress = True)\n",
    "\n",
    "    path_csv = [(default_ds, '/defaults/defaults.csv')]\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path = path_csv)\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='Defaults',\n",
    "                                description='defaults dataset',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fba4e1c",
   "metadata": {},
   "source": [
    "# Data Prep Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8bce7647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting defaults_pipeline/Dataprep_Pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/Dataprep_Pipeline.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from argparse import ArgumentParser as AP\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Get the arguments from pipeline job\n",
    "parser = AP()\n",
    "parser.add_argument('--datafolder', type = str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Get the run context\n",
    "new_run = Run.get_context()\n",
    "\n",
    "# Get the workspace fromthe run\n",
    "ws = new_run.experiment.workspace\n",
    "\n",
    "# Read the input dataset\n",
    "df = new_run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# df = pd.read_csv('defaults.csv')\n",
    "dataPrep = df.drop(['ID'], axis = 1 )\n",
    "all_cols = dataPrep.columns\n",
    "\n",
    "# Check the missing values\n",
    "dataNull = dataPrep.isnull().sum()\n",
    "\n",
    "# Replace the missing values of string variable with mode\n",
    "mode = dataPrep.mode().iloc[0]\n",
    "cols = dataPrep.select_dtypes(include = 'object').columns\n",
    "\n",
    "dataPrep[cols] = dataPrep[cols].fillna(mode)\n",
    "\n",
    "# Replace numerical columns with mean\n",
    "mean = dataPrep.mean()\n",
    "dataPrep = dataPrep.fillna(mean)\n",
    "\n",
    "# Create Dummy variables\n",
    "dataPrep = pd.get_dummies(dataPrep, drop_first = True)\n",
    "\n",
    "# Normalise the data\n",
    "scaler = MinMaxScaler()\n",
    "columns = df.select_dtypes(include = 'number').columns\n",
    "dataPrep[columns] = scaler.fit_transform(dataPrep[columns])\n",
    "\n",
    "\n",
    "\n",
    "# Create the folder if it does not exist\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(args.datafolder, exist_ok=True)\n",
    "path = os.path.join(args.datafloder, 'defaults_prep.csv')\n",
    "dataPrep.to_csv(path, index = False, header = True)\n",
    "\n",
    "# Log null values\n",
    "for columns in all_cols:\n",
    "    new_run.log(columns, dataNull[column])\n",
    "    \n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40bf4eb",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5547bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing defaults_pipeline/Training_Pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/Training_Pipeline.py\n",
    "from azureml.core import Run\n",
    "import argparser\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--datafolder', type = str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Get the context of the experiment run\n",
    "new_run = Run.get_context()\n",
    "\n",
    "# Access the Workspace\n",
    "ws = new_run.experiment.workspace\n",
    "\n",
    "path = os.path.join(args.datafolder, 'defaults_prep.csv')\n",
    "dataPrep = pd.read_csv(path)\n",
    "\n",
    "# Create X and Y\n",
    "y = dataPrep[['Default Next Month_Yes']]\n",
    "X = dataPrep.drop(['Default Next Month_Yes'], axis = 1)\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1234, stratify = True)\n",
    "\n",
    "# Build the logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_predict = lr.predict(X_test)\n",
    "y_prob = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "score = lr.score(X_test, y_test)\n",
    "\n",
    "# Create the confusion matrix dictionary\n",
    "cm_dict = {'schema_type': 'confusion_matrix',\n",
    "           'schema_version': 'v1',\n",
    "           'data': { 'class_labels': ['N', 'Y'],\n",
    "                     'matrix': cm.tolist()\n",
    "                   }\n",
    "          }\n",
    "\n",
    "# Create the scored dataset and upload to outputs\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)\n",
    "\n",
    "y_prob_df = pd.DataFrame(y_prob, columns = ['Scored Probabilities'])\n",
    "y_predict_df = pd.DataFrame(y_predict, columns = ['Scored Label'])\n",
    "\n",
    "scored_dataset = pd.concat([X_test, y_test, y_predict_df, y_prob_df], axis = 1)\n",
    "\n",
    "scored_dataset.to_csv('./outputs/defaults_scored.csv')\n",
    "\n",
    "new_run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62c313",
   "metadata": {},
   "source": [
    "# Define Pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "057403ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "input_ds = ws.datasets.get('Defaults')\n",
    "\n",
    "dataFolder = PipelineData('datafolder',\n",
    "                         datastore = ws.get_default_datastore())\n",
    "\n",
    "# step 01 - Data Preparation\n",
    "dataPrep_step = PythonScriptStep(name = '01 Data Preparation',\n",
    "                                 source_directory = experiment_folder,\n",
    "                                 script_name = 'Dataprep_Pipeline.py',\n",
    "                                 inputs = [input_ds.as_named_input('raw_data')],\n",
    "                                 outputs = [dataFolder],\n",
    "                                 runconfig = run_config,\n",
    "                                 arguments = ['--datafolder', dataFolder])\n",
    "\n",
    "# step 02 - Training the model\n",
    "train_step = PythonScriptStep(name = '02 Train the Model',\n",
    "                                 source_directory = experiment_folder,\n",
    "                                 script_name = 'Training_Pipeline.py',\n",
    "                                 inputs = [dataFolder],\n",
    "                                 runconfig = run_config,\n",
    "                                 arguments = ['--datafolder', dataFolder])\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cb77e3",
   "metadata": {},
   "source": [
    "# Configure and build the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4436fe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step 01 Data Preparation [d2655156][ebd53c01-f3cd-400c-90d9-9fcad0fb0180], (This step is eligible to reuse a previous run's output)\n",
      "Created step 02 TRain the Model [304e9943][a34fbfcd-04cc-4a78-a675-a96068fcea08], (This step is eligible to reuse a previous run's output)\n",
      "Submitted PipelineRun 8d50e49b-4c98-4ec0-8939-e4d9923314da\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/8d50e49b-4c98-4ec0-8939-e4d9923314da?wsid=/subscriptions/f0ec0447-a406-4c0a-922d-f468c99bce13/resourcegroups/AzuremlSDKRG01/workspaces/Azureml-SDK-WS02&tid=f94bf4d9-8097-4794-adf6-a5466ca28563\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235785e863e34c1186050748ee6130ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/8d50e49b-4c98-4ec0-8939-e4d9923314da?wsid=/subscriptions/f0ec0447-a406-4c0a-922d-f468c99bce13/resourcegroups/AzuremlSDKRG01/workspaces/Azureml-SDK-WS02&tid=f94bf4d9-8097-4794-adf6-a5466ca28563\", \"run_id\": \"8d50e49b-4c98-4ec0-8939-e4d9923314da\", \"run_properties\": {\"run_id\": \"8d50e49b-4c98-4ec0-8939-e4d9923314da\", \"created_utc\": \"2022-03-25T09:03:49.368078Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\", \"azureml.continue_on_step_failure\": \"False\", \"azureml.pipelineComponent\": \"pipelinerun\"}, \"tags\": {}, \"end_time_utc\": \"2022-03-25T09:13:53.58918Z\", \"status\": \"Failed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://azuremlsstorage858c34f0b.blob.core.windows.net/azureml/ExperimentRun/dcid.8d50e49b-4c98-4ec0-8939-e4d9923314da/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=iG6Z5vddS3RMV9loT7R7MTzggFjEBQpmBq5NMeYw%2FB0%3D&skoid=e4f56013-7858-4254-b7e2-db1a063b9cc2&sktid=f94bf4d9-8097-4794-adf6-a5466ca28563&skt=2022-03-25T05%3A43%3A19Z&ske=2022-03-26T13%3A53%3A19Z&sks=b&skv=2019-07-07&st=2022-03-25T09%3A04%3A32Z&se=2022-03-25T17%3A14%3A32Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://azuremlsstorage858c34f0b.blob.core.windows.net/azureml/ExperimentRun/dcid.8d50e49b-4c98-4ec0-8939-e4d9923314da/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=ugV%2Fo7sIhBZMCyYSH20gcv9XIBw%2Ftd%2BHHivDM%2BiCcJ8%3D&skoid=e4f56013-7858-4254-b7e2-db1a063b9cc2&sktid=f94bf4d9-8097-4794-adf6-a5466ca28563&skt=2022-03-25T05%3A43%3A19Z&ske=2022-03-26T13%3A53%3A19Z&sks=b&skv=2019-07-07&st=2022-03-25T09%3A04%3A32Z&se=2022-03-25T17%3A14%3A32Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://azuremlsstorage858c34f0b.blob.core.windows.net/azureml/ExperimentRun/dcid.8d50e49b-4c98-4ec0-8939-e4d9923314da/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=igpu7POfGgYH70bcoOV2TvaJHrkropXlQllda74nJv0%3D&skoid=e4f56013-7858-4254-b7e2-db1a063b9cc2&sktid=f94bf4d9-8097-4794-adf6-a5466ca28563&skt=2022-03-25T05%3A43%3A19Z&ske=2022-03-26T13%3A53%3A19Z&sks=b&skv=2019-07-07&st=2022-03-25T09%3A04%3A32Z&se=2022-03-25T17%3A14%3A32Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:10:04\", \"run_number\": \"1648199029\", \"run_queued_details\": {\"status\": \"Failed\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"c1ecbcc6-3910-469c-9bcb-237d7d94c464\", \"name\": \"01 Data Preparation\", \"status\": \"Failed\", \"start_time\": \"2022-03-25T09:12:21.395649Z\", \"created_time\": \"2022-03-25T09:03:51.923704Z\", \"end_time\": \"2022-03-25T09:13:38.179562Z\", \"duration\": \"0:09:46\", \"run_number\": 1648199031, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-03-25T09:03:51.923704Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"\", \"name\": \"02 TRain the Model\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2022-03-25 09:03:52Z] Submitting 1 runs, first five are: d2655156:c1ecbcc6-3910-469c-9bcb-237d7d94c464\\n[2022-03-25 09:13:53Z] Execution of experiment failed, update experiment status and cancel running nodes.\\n\", \"graph\": {\"datasource_nodes\": {\"0d04cb91\": {\"node_id\": \"0d04cb91\", \"name\": \"Defaults\"}}, \"module_nodes\": {\"d2655156\": {\"node_id\": \"d2655156\", \"name\": \"01 Data Preparation\", \"status\": \"Failed\", \"_is_reused\": true, \"run_id\": \"c1ecbcc6-3910-469c-9bcb-237d7d94c464\"}, \"304e9943\": {\"node_id\": \"304e9943\", \"name\": \"02 TRain the Model\", \"status\": \"NotStarted\"}}, \"edges\": [{\"source_node_id\": \"0d04cb91\", \"source_node_name\": \"Defaults\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"d2655156\", \"dst_node_name\": \"01 Data Preparation\"}, {\"source_node_id\": \"d2655156\", \"source_node_name\": \"01 Data Preparation\", \"source_name\": \"datafolder\", \"target_name\": \"datafolder\", \"dst_node_id\": \"304e9943\", \"dst_node_name\": \"02 TRain the Model\"}], \"child_runs\": [{\"run_id\": \"c1ecbcc6-3910-469c-9bcb-237d7d94c464\", \"name\": \"01 Data Preparation\", \"status\": \"Failed\", \"start_time\": \"2022-03-25T09:12:21.395649Z\", \"created_time\": \"2022-03-25T09:03:51.923704Z\", \"end_time\": \"2022-03-25T09:13:38.179562Z\", \"duration\": \"0:09:46\", \"run_number\": 1648199031, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2022-03-25T09:03:51.923704Z\", \"is_reused\": \"Yes\"}, {\"run_id\": \"\", \"name\": \"02 TRain the Model\", \"status\": \"NotStarted\", \"start_time\": \"\", \"created_time\": \"\", \"end_time\": \"\", \"duration\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.38.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 8d50e49b-4c98-4ec0-8939-e4d9923314da\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/8d50e49b-4c98-4ec0-8939-e4d9923314da?wsid=/subscriptions/f0ec0447-a406-4c0a-922d-f468c99bce13/resourcegroups/AzuremlSDKRG01/workspaces/Azureml-SDK-WS02&tid=f94bf4d9-8097-4794-adf6-a5466ca28563\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: c1ecbcc6-3910-469c-9bcb-237d7d94c464\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/c1ecbcc6-3910-469c-9bcb-237d7d94c464?wsid=/subscriptions/f0ec0447-a406-4c0a-922d-f468c99bce13/resourcegroups/AzuremlSDKRG01/workspaces/Azureml-SDK-WS02&tid=f94bf4d9-8097-4794-adf6-a5466ca28563\n",
      "StepRun( 01 Data Preparation ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2022/03/25 09:03:00 Downloading source code...\n",
      "2022/03/25 09:03:01 Finished downloading source code\n",
      "2022/03/25 09:03:02 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2022/03/25 09:03:02 Successfully set up Docker network: acb_default_network\n",
      "2022/03/25 09:03:02 Setting up Docker configuration...\n",
      "2022/03/25 09:03:02 Successfully set up Docker configuration\n",
      "2022/03/25 09:03:02 Logging in to registry: c660939c46a0404a80eba5b1b21d88cc.azurecr.io\n",
      "2022/03/25 09:03:04 Successfully logged into c660939c46a0404a80eba5b1b21d88cc.azurecr.io\n",
      "2022/03/25 09:03:04 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/03/25 09:03:04 Scanning for dependencies...\n",
      "2022/03/25 09:03:05 Successfully scanned dependencies\n",
      "2022/03/25 09:03:05 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/21 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1@sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf\n",
      "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1@sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n",
      "2f94e549220a: Already exists\n",
      "2b2d92136c10: Pulling fs layer\n",
      "0b412d2669ed: Pulling fs layer\n",
      "805003cfcee6: Pulling fs layer\n",
      "ad877dc53455: Pulling fs layer\n",
      "afa783568628: Pulling fs layer\n",
      "d67cf86adb17: Pulling fs layer\n",
      "82770c3b2808: Pulling fs layer\n",
      "c991e53ceb53: Pulling fs layer\n",
      "ad877dc53455: Waiting\n",
      "afa783568628: Waiting\n",
      "d67cf86adb17: Waiting\n",
      "82770c3b2808: Waiting\n",
      "c991e53ceb53: Waiting\n",
      "0b412d2669ed: Verifying Checksum\n",
      "0b412d2669ed: Download complete\n",
      "805003cfcee6: Verifying Checksum\n",
      "805003cfcee6: Download complete\n",
      "afa783568628: Verifying Checksum\n",
      "afa783568628: Download complete\n",
      "2b2d92136c10: Verifying Checksum\n",
      "2b2d92136c10: Download complete\n",
      "82770c3b2808: Verifying Checksum\n",
      "82770c3b2808: Download complete\n",
      "ad877dc53455: Verifying Checksum\n",
      "ad877dc53455: Download complete\n",
      "c991e53ceb53: Verifying Checksum\n",
      "c991e53ceb53: Download complete\n",
      "d67cf86adb17: Verifying Checksum\n",
      "d67cf86adb17: Download complete\n",
      "2b2d92136c10: Pull complete\n",
      "0b412d2669ed: Pull complete\n",
      "805003cfcee6: Pull complete\n",
      "ad877dc53455: Pull complete\n",
      "afa783568628: Pull complete\n",
      "d67cf86adb17: Pull complete\n",
      "82770c3b2808: Pull complete\n",
      "c991e53ceb53: Pull complete\n",
      "Digest: sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20220113.v1@sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf\n",
      " ---> 54296612fc48\n",
      "Step 2/21 : USER root\n",
      " ---> Running in 37463ce74b92\n",
      "Removing intermediate container 37463ce74b92\n",
      " ---> 9d31a33f6022\n",
      "Step 3/21 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in b188afc994e3\n",
      "Removing intermediate container b188afc994e3\n",
      " ---> 12aa2ccf6720\n",
      "Step 4/21 : WORKDIR /\n",
      " ---> Running in bfcb4609601e\n",
      "Removing intermediate container bfcb4609601e\n",
      " ---> 1363d6030c4e\n",
      "Step 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 54a2992c3d5c\n",
      "Step 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in ca37169efa60\n",
      "Removing intermediate container ca37169efa60\n",
      " ---> 8d6b6311c044\n",
      "Step 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 2a8bb37b3a5b\n",
      "Step 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 9ea5ecf57517\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "python-dateutil-2.8. | 224 KB    |            |   0% \n",
      "python-dateutil-2.8. | 224 KB    | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.1.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.1.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "numpy-base-1.19.1    | 5.2 MB    |            |   0% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 52 KB     |            |   0% \n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
      "\n",
      "joblib-0.17.0        | 205 KB    |            |   0% \n",
      "joblib-0.17.0        | 205 KB    | ########## | 100% \n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \n",
      "python-3.6.2         | 27.0 MB   | ###8       |  38% \n",
      "python-3.6.2         | 27.0 MB   | #########4 |  94% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "\n",
      "scikit-learn-0.23.2  | 6.9 MB    |            |   0% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "\n",
      "mkl_fft-1.2.0        | 164 KB    |            |   0% \n",
      "mkl_fft-1.2.0        | 164 KB    | ########## | 100% \n",
      "\n",
      "pip-20.2.4           | 2.0 MB    |            |   0% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "wheel-0.35.1         | 36 KB     |            |   0% \n",
      "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 128 KB    |            |   0% \n",
      "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.2 MB    |            |   0% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "\n",
      "six-1.15.0           | 13 KB     |            |   0% \n",
      "six-1.15.0           | 13 KB     | ########## | 100% \n",
      "\n",
      "setuptools-50.3.0    | 891 KB    |            |   0% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "\n",
      "pandas-1.1.3         | 10.5 MB   |            |   0% \n",
      "pandas-1.1.3         | 10.5 MB   | #########1 |  92% \n",
      "pandas-1.1.3         | 10.5 MB   | ########## | 100% \n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \n",
      "mkl-2019.4           | 204.1 MB  | 4          |   4% \n",
      "mkl-2019.4           | 204.1 MB  | 9          |  10% \n",
      "mkl-2019.4           | 204.1 MB  | #4         |  15% \n",
      "mkl-2019.4           | 204.1 MB  | #9         |  20% \n",
      "mkl-2019.4           | 204.1 MB  | ##3        |  23% \n",
      "mkl-2019.4           | 204.1 MB  | ##9        |  29% \n",
      "mkl-2019.4           | 204.1 MB  | ###4       |  35% \n",
      "mkl-2019.4           | 204.1 MB  | ####1      |  42% \n",
      "mkl-2019.4           | 204.1 MB  | ####7      |  48% \n",
      "mkl-2019.4           | 204.1 MB  | #####3     |  54% \n",
      "mkl-2019.4           | 204.1 MB  | ######     |  60% \n",
      "mkl-2019.4           | 204.1 MB  | ######7    |  67% \n",
      "mkl-2019.4           | 204.1 MB  | #######4   |  74% \n",
      "mkl-2019.4           | 204.1 MB  | ########   |  81% \n",
      "mkl-2019.4           | 204.1 MB  | ########7  |  87% \n",
      "mkl-2019.4           | 204.1 MB  | #########4 |  94% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \n",
      "\n",
      "pytz-2020.1          | 239 KB    |            |   0% \n",
      "pytz-2020.1          | 239 KB    | ########## | 100% \n",
      "pytz-2020.1          | 239 KB    | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "\n",
      "scipy-1.5.2          | 18.5 MB   |            |   0% \n",
      "scipy-1.5.2          | 18.5 MB   | ####6      |  46% \n",
      "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
      "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "\n",
      "intel-openmp-2020.2  | 947 KB    |            |   0% \n",
      "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
      "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "numpy-1.19.1         | 20 KB     |            |   0% \n",
      "numpy-1.19.1         | 20 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.a4ugpwj6.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults~=1.38.0\n",
      "  Downloading azureml_defaults-1.38.0-py3-none-any.whl (3.0 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting azureml-core~=1.38.0\n",
      "  Downloading azureml_core-1.38.0.post2-py3-none-any.whl (2.5 MB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azureml-inference-server-http~=0.4.1\n",
      "  Downloading azureml_inference_server_http-0.4.11-py3-none-any.whl (38 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.38.0\n",
      "  Downloading azureml_dataset_runtime-1.38.0-py3-none-any.whl (3.5 kB)\n",
      "Collecting msal<2.0.0,>=1.15.0\n",
      "  Downloading msal-1.17.0-py2.py3-none-any.whl (79 kB)\n",
      "Collecting azure-mgmt-containerregistry<9.0.0,>=8.2.0\n",
      "  Downloading azure_mgmt_containerregistry-8.2.0-py2.py3-none-any.whl (928 kB)\n",
      "Collecting pyopenssl<22.0.0\n",
      "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
      "Collecting urllib3<=1.26.7,>=1.23\n",
      "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "Collecting azure-mgmt-resource<21.0.0,>=15.0.0\n",
      "  Downloading azure_mgmt_resource-20.1.0-py3-none-any.whl (2.3 MB)\n",
      "Collecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pkginfo\n",
      "  Downloading pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\n",
      "Collecting azure-core<1.22\n",
      "  Downloading azure_core-1.21.1-py2.py3-none-any.whl (178 kB)\n",
      "Collecting packaging<22.0,>=20.0\n",
      "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting humanfriendly<11.0,>=4.7\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting contextlib2<22.0.0\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting msrest<1.0.0,>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting requests[socks]<3.0.0,>=2.19.1\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting knack~=0.8.2\n",
      "  Downloading knack-0.8.2-py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/lib/python3.6/site-packages (from azureml-core~=1.38.0->azureml-defaults~=1.38.0->-r /azureml-environment-setup/condaenv.a4ugpwj6.requirements.txt (line 1)) (2.8.1)\n",
      "Collecting docker<6.0.0\n",
      "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "Collecting ndg-httpsclient<=0.5.1\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting paramiko<3.0.0,>=2.0.8\n",
      "  Downloading paramiko-2.10.3-py2.py3-none-any.whl (211 kB)\n",
      "Collecting msal-extensions<0.4,>=0.3.0\n",
      "  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting msrestazure<=0.6.4,>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0\n",
      "  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/lib/python3.6/site-packages (from azureml-core~=1.38.0->azureml-defaults~=1.38.0->-r /azureml-environment-setup/condaenv.a4ugpwj6.requirements.txt (line 1)) (2020.1)\n",
      "Collecting argcomplete<2.0\n",
      "  Downloading argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
      "Collecting adal<=1.2.7,>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting azure-mgmt-storage<20.0.0,>=16.0.0\n",
      "  Downloading azure_mgmt_storage-19.1.0-py3-none-any.whl (1.8 MB)\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting jmespath<1.0.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting gunicorn==20.1.0; platform_system != \"Windows\"\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting inference-schema==1.3.0\n",
      "  Downloading inference_schema-1.3.0-py3-none-any.whl (19 kB)\n",
      "Collecting Werkzeug<2.0,>=0.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting itsdangerous<2.0,>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting click<8.0,>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Jinja2<3.1,>=2.10.1\n",
      "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "Collecting azureml-dataprep<2.27.0a,>=2.26.0a\n",
      "  Downloading azureml_dataprep-2.26.0-py3-none-any.whl (39.4 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy!=1.19.3; sys_platform == \"linux\" in /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/lib/python3.6/site-packages (from azureml-dataset-runtime[fuse]~=1.38.0->azureml-defaults~=1.38.0->-r /azureml-environment-setup/condaenv.a4ugpwj6.requirements.txt (line 1)) (1.19.1)\n",
      "Collecting pyarrow<4.0.0,>=0.17.0\n",
      "  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
      "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.2 in /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/lib/python3.6/site-packages (from pyopenssl<22.0.0->azureml-core~=1.38.0->azureml-defaults~=1.38.0->-r /azureml-environment-setup/condaenv.a4ugpwj6.requirements.txt (line 1)) (1.15.0)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2\n",
      "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/lib/python3.6/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.38.0->azureml-defaults~=1.38.0->-r /azureml-environment-setup/condaenv.a4ugpwj6.requirements.txt (line 1)) (2020.6.20)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting idna<4,>=2.5; python_version >= \"3\"\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer~=2.0.0; python_version >= \"3\"\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6; extra == \"socks\"\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pygments\n",
      "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (603 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.3.1-py3-none-any.whl (54 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (61 kB)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "Collecting portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\"\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.15.0-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (405 kB)\n",
      "Collecting importlib-metadata<5,>=0.23; python_version == \"3.6\"\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=3.0 in /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/lib/python3.6/site-packages (from gunicorn==20.1.0; platform_system != \"Windows\"->azureml-inference-server-http~=0.4.1->azureml-defaults~=1.38.0->-r /azureml-environment-setup/condaenv.a4ugpwj6.requirements.txt (line 1)) (50.3.0.post20201006)\n",
      "Collecting wrapt<=1.12.1,>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl (30 kB)\n",
      "Collecting azure-identity==1.7.0\n",
      "  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\n",
      "Collecting cloudpickle<3.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Collecting azureml-dataprep-native<39.0.0,>=38.0.0\n",
      "  Downloading azureml_dataprep_native-38.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)\n",
      "Collecting azureml-dataprep-rslex~=2.2.0dev0\n",
      "  Downloading azureml_dataprep_rslex-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (13.4 MB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.7.0-py3-none-any.whl (20 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, wrapt\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=14b615eab42f8da700bd76cd7972700819d7ee5a7bf898dbbc8eb2b5a27f88ac\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=c482976fb1443ef6e4b18c37f5d6db4fe84a85659b4044d90b54e80cceb1e2de\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69872 sha256=fe1e78ccd30ead53396378c6511a13d635d0592b515dcccfe4e9d2b32bdf6768\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built json-logging-py fusepy wrapt\n",
      "Installing collected packages: json-logging-py, pycparser, cffi, cryptography, idna, charset-normalizer, urllib3, PySocks, requests, PyJWT, msal, azure-common, azure-core, azure-mgmt-core, oauthlib, requests-oauthlib, isodate, msrest, azure-mgmt-containerregistry, pyopenssl, azure-mgmt-resource, azure-mgmt-keyvault, backports.weakref, backports.tempfile, pkginfo, pyparsing, packaging, humanfriendly, contextlib2, zipp, typing-extensions, importlib-metadata, argcomplete, colorama, pygments, jmespath, tabulate, pyyaml, knack, websocket-client, docker, pyasn1, ndg-httpsclient, bcrypt, pynacl, paramiko, portalocker, msal-extensions, adal, msrestazure, azure-mgmt-authorization, jeepney, SecretStorage, pathspec, azure-mgmt-storage, jsonpickle, azure-graphrbac, azureml-core, configparser, gunicorn, wrapt, inference-schema, Werkzeug, itsdangerous, MarkupSafe, Jinja2, click, flask, applicationinsights, azureml-inference-server-http, azure-identity, cloudpickle, azureml-dataprep-native, distro, dotnetcore2, azureml-dataprep-rslex, azureml-dataprep, pyarrow, fusepy, azureml-dataset-runtime, azureml-defaults\n",
      "Successfully installed Jinja2-3.0.3 MarkupSafe-2.0.1 PyJWT-2.3.0 PySocks-1.7.1 SecretStorage-3.3.1 Werkzeug-1.0.1 adal-1.2.7 applicationinsights-0.11.10 argcomplete-1.12.3 azure-common-1.1.28 azure-core-1.21.1 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.2.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-20.1.0 azure-mgmt-storage-19.1.0 azureml-core-1.38.0.post2 azureml-dataprep-2.26.0 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.2.0 azureml-dataset-runtime-1.38.0 azureml-defaults-1.38.0 azureml-inference-server-http-0.4.11 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.0 cffi-1.15.0 charset-normalizer-2.0.12 click-7.1.2 cloudpickle-2.0.0 colorama-0.4.4 configparser-3.7.4 contextlib2-21.6.0 cryptography-36.0.2 distro-1.7.0 docker-5.0.3 dotnetcore2-2.1.23 flask-1.0.3 fusepy-3.0.1 gunicorn-20.1.0 humanfriendly-10.0 idna-3.3 importlib-metadata-4.8.3 inference-schema-1.3.0 isodate-0.6.1 itsdangerous-1.1.0 jeepney-0.7.1 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.1.0 knack-0.8.2 msal-1.17.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.2.0 packaging-21.3 paramiko-2.10.3 pathspec-0.9.0 pkginfo-1.8.2 portalocker-2.4.0 pyarrow-3.0.0 pyasn1-0.4.8 pycparser-2.21 pygments-2.11.2 pynacl-1.5.0 pyopenssl-21.0.0 pyparsing-3.0.7 pyyaml-6.0 requests-2.27.1 requests-oauthlib-1.3.1 tabulate-0.8.9 typing-extensions-4.1.1 urllib3-1.26.7 websocket-client-1.3.1 wrapt-1.12.1 zipp-3.6.0\n",
      "\n",
      "done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 4.12.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0m#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "WARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 9ea5ecf57517\n",
      " ---> 7cc8b497306d\n",
      "Step 9/21 : ENV PATH /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/bin:$PATH\n",
      " ---> Running in 233f077813db\n",
      "Removing intermediate container 233f077813db\n",
      " ---> 76e57fe209bf\n",
      "Step 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> d67dbca35404\n",
      "Step 11/21 : RUN echo \"Copying environment context\"\n",
      " ---> Running in bb6aea0ab081\n",
      "Copying environment context\n",
      "Removing intermediate container bb6aea0ab081\n",
      " ---> 1456df858f81\n",
      "Step 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 5887e01a66c7\n",
      "Step 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc\n",
      " ---> Running in f9d9a088251d\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container f9d9a088251d\n",
      " ---> d84d3b4d200b\n",
      "Step 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc\n",
      " ---> Running in 599621b58dbd\n",
      "Removing intermediate container 599621b58dbd\n",
      " ---> 76834e8fa146\n",
      "Step 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 3be30c785341\n",
      "Removing intermediate container 3be30c785341\n",
      " ---> edda2b67af6b\n",
      "Step 16/21 : ENV CONDA_DEFAULT_ENV=azureml_d9271587e78e8fd4e49fcb4d1af951bc CONDA_PREFIX=/azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc\n",
      " ---> Running in 6fea70c98581\n",
      "Removing intermediate container 6fea70c98581\n",
      " ---> ad11b19a991a\n",
      "Step 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 4f79ac504a6d\n",
      "Step 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 5d24fa27b60e\n",
      "Removing intermediate container 5d24fa27b60e\n",
      " ---> 1b3f5e144668\n",
      "Step 19/21 : RUN rm -rf azureml-environment-setup\n",
      " ---> Running in db6586a7ac94\n",
      "Removing intermediate container db6586a7ac94\n",
      " ---> 0420df609740\n",
      "Step 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 836b04e4caef\n",
      "Removing intermediate container 836b04e4caef\n",
      " ---> 59e721776dca\n",
      "Step 21/21 : CMD [\"bash\"]\n",
      " ---> Running in 0293782db325\n",
      "Removing intermediate container 0293782db325\n",
      " ---> ed7e322e74bc\n",
      "Successfully built ed7e322e74bc\n",
      "Successfully tagged c660939c46a0404a80eba5b1b21d88cc.azurecr.io/azureml/azureml_452fd7b3ac890afc00e67cdb6f50fad8:latest\n",
      "Successfully tagged c660939c46a0404a80eba5b1b21d88cc.azurecr.io/azureml/azureml_452fd7b3ac890afc00e67cdb6f50fad8:1\n",
      "2022/03/25 09:06:39 Successfully executed container: acb_step_0\n",
      "2022/03/25 09:06:39 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/03/25 09:06:39 Pushing image: c660939c46a0404a80eba5b1b21d88cc.azurecr.io/azureml/azureml_452fd7b3ac890afc00e67cdb6f50fad8:1, attempt 1\n",
      "The push refers to repository [c660939c46a0404a80eba5b1b21d88cc.azurecr.io/azureml/azureml_452fd7b3ac890afc00e67cdb6f50fad8]\n",
      "8266426684c2: Preparing\n",
      "329539029199: Preparing\n",
      "2ee71e9ea629: Preparing\n",
      "08cae807d6e4: Preparing\n",
      "97652ef29156: Preparing\n",
      "e7f3f1507a82: Preparing\n",
      "d00ae8329ef4: Preparing\n",
      "3283e70fe49f: Preparing\n",
      "fc5f50815f0e: Preparing\n",
      "d574c775d6a1: Preparing\n",
      "5a63f0a64b99: Preparing\n",
      "cfd97667b73b: Preparing\n",
      "dda643f89a6b: Preparing\n",
      "06f4d263b25f: Preparing\n",
      "5ecae586bbba: Preparing\n",
      "eb66e810a3df: Preparing\n",
      "081c0f822cac: Preparing\n",
      "0be4c2d28ad7: Preparing\n",
      "40a154bd3352: Preparing\n",
      "e7f3f1507a82: Waiting\n",
      "d00ae8329ef4: Waiting\n",
      "3283e70fe49f: Waiting\n",
      "fc5f50815f0e: Waiting\n",
      "d574c775d6a1: Waiting\n",
      "5a63f0a64b99: Waiting\n",
      "cfd97667b73b: Waiting\n",
      "dda643f89a6b: Waiting\n",
      "06f4d263b25f: Waiting\n",
      "5ecae586bbba: Waiting\n",
      "eb66e810a3df: Waiting\n",
      "081c0f822cac: Waiting\n",
      "0be4c2d28ad7: Waiting\n",
      "40a154bd3352: Waiting\n",
      "08cae807d6e4: Pushed\n",
      "329539029199: Pushed\n",
      "97652ef29156: Pushed\n",
      "8266426684c2: Pushed\n",
      "2ee71e9ea629: Pushed\n",
      "fc5f50815f0e: Pushed\n",
      "d00ae8329ef4: Pushed\n",
      "3283e70fe49f: Pushed\n",
      "d574c775d6a1: Pushed\n",
      "5a63f0a64b99: Pushed\n",
      "cfd97667b73b: Pushed\n",
      "dda643f89a6b: Pushed\n",
      "06f4d263b25f: Pushed\n",
      "eb66e810a3df: Pushed\n",
      "081c0f822cac: Pushed\n",
      "5ecae586bbba: Pushed\n",
      "40a154bd3352: Pushed\n",
      "0be4c2d28ad7: Pushed\n",
      "e7f3f1507a82: Pushed\n",
      "1: digest: sha256:a6b14ac7e2f5a65b3a9151aca9afb32718f41345af8dfc029891e3ee2ebb00c8 size: 4307\n",
      "2022/03/25 09:08:11 Successfully pushed image: c660939c46a0404a80eba5b1b21d88cc.azurecr.io/azureml/azureml_452fd7b3ac890afc00e67cdb6f50fad8:1\n",
      "2022/03/25 09:08:11 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2022/03/25 09:08:11 Pushing image: c660939c46a0404a80eba5b1b21d88cc.azurecr.io/azureml/azureml_452fd7b3ac890afc00e67cdb6f50fad8:latest, attempt 1\n",
      "The push refers to repository [c660939c46a0404a80eba5b1b21d88cc.azurecr.io/azureml/azureml_452fd7b3ac890afc00e67cdb6f50fad8]\n",
      "8266426684c2: Preparing\n",
      "329539029199: Preparing\n",
      "2ee71e9ea629: Preparing\n",
      "08cae807d6e4: Preparing\n",
      "97652ef29156: Preparing\n",
      "e7f3f1507a82: Preparing\n",
      "d00ae8329ef4: Preparing\n",
      "3283e70fe49f: Preparing\n",
      "fc5f50815f0e: Preparing\n",
      "d574c775d6a1: Preparing\n",
      "5a63f0a64b99: Preparing\n",
      "cfd97667b73b: Preparing\n",
      "dda643f89a6b: Preparing\n",
      "06f4d263b25f: Preparing\n",
      "5ecae586bbba: Preparing\n",
      "eb66e810a3df: Preparing\n",
      "081c0f822cac: Preparing\n",
      "0be4c2d28ad7: Preparing\n",
      "40a154bd3352: Preparing\n",
      "e7f3f1507a82: Waiting\n",
      "d00ae8329ef4: Waiting\n",
      "3283e70fe49f: Waiting\n",
      "fc5f50815f0e: Waiting\n",
      "d574c775d6a1: Waiting\n",
      "5a63f0a64b99: Waiting\n",
      "cfd97667b73b: Waiting\n",
      "dda643f89a6b: Waiting\n",
      "06f4d263b25f: Waiting\n",
      "5ecae586bbba: Waiting\n",
      "eb66e810a3df: Waiting\n",
      "081c0f822cac: Waiting\n",
      "0be4c2d28ad7: Waiting\n",
      "40a154bd3352: Waiting\n",
      "2ee71e9ea629: Layer already exists\n",
      "e7f3f1507a82: Layer already exists\n",
      "d00ae8329ef4: Layer already exists\n",
      "3283e70fe49f: Layer already exists\n",
      "fc5f50815f0e: Layer already exists\n",
      "d574c775d6a1: Layer already exists\n",
      "5a63f0a64b99: Layer already exists\n",
      "cfd97667b73b: Layer already exists\n",
      "dda643f89a6b: Layer already exists\n",
      "06f4d263b25f: Layer already exists\n",
      "5ecae586bbba: Layer already exists\n",
      "eb66e810a3df: Layer already exists\n",
      "081c0f822cac: Layer already exists\n",
      "0be4c2d28ad7: Layer already exists\n",
      "40a154bd3352: Layer already exists\n",
      "8266426684c2: Layer already exists\n",
      "97652ef29156: Layer already exists\n",
      "329539029199: Layer already exists\n",
      "08cae807d6e4: Layer already exists\n",
      "latest: digest: sha256:a6b14ac7e2f5a65b3a9151aca9afb32718f41345af8dfc029891e3ee2ebb00c8 size: 4307\n",
      "2022/03/25 09:08:14 Successfully pushed image: c660939c46a0404a80eba5b1b21d88cc.azurecr.io/azureml/azureml_452fd7b3ac890afc00e67cdb6f50fad8:latest\n",
      "2022/03/25 09:08:14 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 214.675554)\n",
      "2022/03/25 09:08:14 Populating digests for step ID: acb_step_0...\n",
      "2022/03/25 09:08:15 Successfully populated digests for step ID: acb_step_0\n",
      "2022/03/25 09:08:15 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 91.739723)\n",
      "2022/03/25 09:08:15 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 2.919643)\n",
      "2022/03/25 09:08:15 The following dependencies were found:\n",
      "2022/03/25 09:08:15 \n",
      "- image:\n",
      "    registry: c660939c46a0404a80eba5b1b21d88cc.azurecr.io\n",
      "    repository: azureml/azureml_452fd7b3ac890afc00e67cdb6f50fad8\n",
      "    tag: latest\n",
      "    digest: sha256:a6b14ac7e2f5a65b3a9151aca9afb32718f41345af8dfc029891e3ee2ebb00c8\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20220113.v1\n",
      "    digest: sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: c660939c46a0404a80eba5b1b21d88cc.azurecr.io\n",
      "    repository: azureml/azureml_452fd7b3ac890afc00e67cdb6f50fad8\n",
      "    tag: \"1\"\n",
      "    digest: sha256:a6b14ac7e2f5a65b3a9151aca9afb32718f41345af8dfc029891e3ee2ebb00c8\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20220113.v1\n",
      "    digest: sha256:024c1f016bc4fe902601239d41f526ea987816ba25b524c22c4cb3cdd8db6ebf\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: ch1 was successful after 5m15s\n",
      "\n",
      "StepRun(01 Data Preparation) Execution Summary\n",
      "===============================================\n",
      "StepRun( 01 Data Preparation ) Status: Failed\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"{'code': ExecutionFailed, 'message': [{\\\"exit_code\\\":1,\\\"error_message\\\":\\\"Execution failed with error: Saving Data...\\\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\\\n1 items cleaning up...\\\\nCleanup took 0.0708913803100586 seconds\\\\n[stderr]Traceback (most recent call last):\\\\n[stderr]  File \\\\\\\"Dataprep_Pipeline.py\\\\\\\", line 53, in <module>\\\\n[stderr]    path = os.path.join(args.datafloder, 'defaults_prep.csv')\\\\n[stderr]AttributeError: 'Namespace' object has no attribute 'datafloder'\\\\n[stderr]\\\\n\\\",\\\"process_name\\\":\\\"/azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/bin/python\\\",\\\"error_file\\\":\\\"user_logs/std_log.txt\\\"}], 'target': , 'category': UserError, 'error_details': [{'key': exit_codes, 'value': 1}, ], 'inner_error': null}\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"{'code': ExecutionFailed, 'message': [{\\\\\\\"exit_code\\\\\\\":1,\\\\\\\"error_message\\\\\\\":\\\\\\\"Execution failed with error: Saving Data...\\\\\\\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\\\\\\\n1 items cleaning up...\\\\\\\\nCleanup took 0.0708913803100586 seconds\\\\\\\\n[stderr]Traceback (most recent call last):\\\\\\\\n[stderr]  File \\\\\\\\\\\\\\\"Dataprep_Pipeline.py\\\\\\\\\\\\\\\", line 53, in <module>\\\\\\\\n[stderr]    path = os.path.join(args.datafloder, 'defaults_prep.csv')\\\\\\\\n[stderr]AttributeError: 'Namespace' object has no attribute 'datafloder'\\\\\\\\n[stderr]\\\\\\\\n\\\\\\\",\\\\\\\"process_name\\\\\\\":\\\\\\\"/azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/bin/python\\\\\\\",\\\\\\\"error_file\\\\\\\":\\\\\\\"user_logs/std_log.txt\\\\\\\"}], 'target': , 'category': UserError, 'error_details': [{'key': exit_codes, 'value': 1}, ], 'inner_error': null}\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline submitted for execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m RunDetails(new_pipeline_run)\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 17\u001b[0m \u001b[43mnew_pipeline_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow_output\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:295\u001b[0m, in \u001b[0;36mPipelineRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[43mstep_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtime_elapsed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;66;03m# If there are package conflicts in the user's environment, the run rehydration\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# will not work and we will receive a Run object instead of StepRun.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# Run.wait_for_completion() does not have a parameter timeout_seconds, which\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# will generate a TypeError here.  As a workaround, call the method without\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# this parameter.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(step_run, StepRun):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:737\u001b[0m, in \u001b[0;36mStepRun.wait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show_output:\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 737\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream_run_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    740\u001b[0m         error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    741\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetails for canceling the run can be found here: \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    743\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/pipeline/core/run.py:830\u001b[0m, in \u001b[0;36mStepRun._stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mand\u001b[39;00m raise_on_error:\n\u001b[0;32m--> 830\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ActivityFailedException(error_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(error, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_details)\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"{'code': ExecutionFailed, 'message': [{\\\"exit_code\\\":1,\\\"error_message\\\":\\\"Execution failed with error: Saving Data...\\\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\\\n1 items cleaning up...\\\\nCleanup took 0.0708913803100586 seconds\\\\n[stderr]Traceback (most recent call last):\\\\n[stderr]  File \\\\\\\"Dataprep_Pipeline.py\\\\\\\", line 53, in <module>\\\\n[stderr]    path = os.path.join(args.datafloder, 'defaults_prep.csv')\\\\n[stderr]AttributeError: 'Namespace' object has no attribute 'datafloder'\\\\n[stderr]\\\\n\\\",\\\"process_name\\\":\\\"/azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/bin/python\\\",\\\"error_file\\\":\\\"user_logs/std_log.txt\\\"}], 'target': , 'category': UserError, 'error_details': [{'key': exit_codes, 'value': 1}, ], 'inner_error': null}\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"{'code': ExecutionFailed, 'message': [{\\\\\\\"exit_code\\\\\\\":1,\\\\\\\"error_message\\\\\\\":\\\\\\\"Execution failed with error: Saving Data...\\\\\\\\nCleaning up all outstanding Run operations, waiting 300.0 seconds\\\\\\\\n1 items cleaning up...\\\\\\\\nCleanup took 0.0708913803100586 seconds\\\\\\\\n[stderr]Traceback (most recent call last):\\\\\\\\n[stderr]  File \\\\\\\\\\\\\\\"Dataprep_Pipeline.py\\\\\\\\\\\\\\\", line 53, in <module>\\\\\\\\n[stderr]    path = os.path.join(args.datafloder, 'defaults_prep.csv')\\\\\\\\n[stderr]AttributeError: 'Namespace' object has no attribute 'datafloder'\\\\\\\\n[stderr]\\\\\\\\n\\\\\\\",\\\\\\\"process_name\\\\\\\":\\\\\\\"/azureml-envs/azureml_d9271587e78e8fd4e49fcb4d1af951bc/bin/python\\\\\\\",\\\\\\\"error_file\\\\\\\":\\\\\\\"user_logs/std_log.txt\\\\\\\"}], 'target': , 'category': UserError, 'error_details': [{'key': exit_codes, 'value': 1}, ], 'inner_error': null}\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "steps = [dataPrep_step, train_step]\n",
    "\n",
    "new_pipeline = Pipeline(workspace = ws,\n",
    "                        steps = steps)\n",
    "\n",
    "# Create the experiment and run the pipeline\n",
    "from azureml.core import Experiment\n",
    "\n",
    "new_experiment = Experiment(workspace = ws, name = 'PpelineExp01')\n",
    "new_pipeline_run = new_experiment.submit(new_pipeline)\n",
    "\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "RunDetails(new_pipeline_run).show()\n",
    "new_pipeline_run.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ef086dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7b25fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b8d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ff040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15320e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ccbdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ecb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2474c99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
